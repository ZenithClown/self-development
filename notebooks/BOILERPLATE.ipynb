{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = \"center\">Boilerplate/Template Design</h1>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Objective:** The file provides a simple *boilerplate* to concentrate on what is necessary, and stop doing same tasks! The boilerplate is also configured with certain [**nbextensions**](https://gitlab.com/ZenithClown/computer-configurations-and-setups) that I personally use. Install them, if required, else ignore them as they do not participate in any type of code-optimizations. For any new project *edit* this file or `File > Make a Copy` to get started with the project. Some settings and configurations are already provided, as mentioned below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Imports\n",
    "\n",
    "**PEP8 Style Guide** lists out the following [*guidelines*](https://peps.python.org/pep-0008/#imports) for imports:\n",
    " 1. Imports should be on separate lines,\n",
    " 2. Import order should be:\n",
    "    * standard library/modules,\n",
    "    * related third party imports,\n",
    "    * local application/user defined imports\n",
    " 3. Wildcard import (`*`) should be avoided, else specifically tagged with **`# noqa: F403`** as per `flake8` [(ignoring errors)](https://flake8.pycqa.org/en/3.1.1/user/ignoring-errors.html).\n",
    " 4. Avoid using relative imports; use explicit imports instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T05:35:49.395805Z",
     "start_time": "2022-05-25T05:35:49.385719Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys # append additional directories to list\n",
    "import warnings # display specified user warnings as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T05:23:27.363635Z",
     "start_time": "2022-05-25T05:23:27.351744Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import walk # get list of files in a directory and subdirectory\n",
    "from time import time # get the epoch time, helpful in saving files\n",
    "from time import ctime # print computer time in human redable format\n",
    "from os import makedirs # create directories dynamically\n",
    "from os.path import join # joins mutiple path without os dependency\n",
    "# from copy import deepcopy # make an actual copy of immutable objects like `str`\n",
    "# from tqdm import tqdm as TQ # for displaying a nice progress bar while running\n",
    "# from uuid import uuid1 as UUID # for generating unique identifier\n",
    "from datetime import datetime as dt # formatting/defining datetime objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**`logging`**](https://docs.python.org/3/howto/logging.html) is a standard python module that is meant for tracking any events that happen during any software/code operations. This module is super powerful and helpful for code debugging and other purposes. The next section defines a `logging` configuration in **`../logs/`** directory. Modify the **`LOGS_DIR`** variable under *Global Arguments* to change the default directory. The module is configured with a simplistic approach, such that any `print())` statement can be update to `logging.LEVEL_NAME()` and the code will work. Use logging operations like:\n",
    "\n",
    "```python\n",
    " >> logging.debug(\"This is a Debug Message.\")\n",
    " >> logging.info(\"This is a Information Message.\")\n",
    " >> logging.warning(\"This is a Warning Message.\")\n",
    " >> logging.error(\"This is a ERROR Message.\")\n",
    " >> logging.critical(\"This is a CRITICAL Message.\")\n",
    "```\n",
    "\n",
    "Note: some directories related to logging is created by default. This can be updated/changed in the following configuration section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T05:23:15.469063Z",
     "start_time": "2022-05-25T05:23:15.463661Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging # configure logging on `global arguments` section, as file path is required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Frame, NumPy and Visualization Libraries\n",
    "\n",
    "Daily use libraries like `pandas`, `numpy` is available for import along with *display* settings in a python notebook. Generally, I prefer to use `matplotlib` and `seaborn` which is imported below with certain configurations as mentioned. Stylesheet is available [here](https://gitlab.com/ZenithClown/computer-configurations-and-setups/-/blob/master/default-style.mplstyle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "%precision 3\n",
    "# %matplotlib inline\n",
    "# sns.set_style('whitegrid');\n",
    "# plt.style.use('default-style'); # https://gitlab.com/ZenithClown/computer-configurations-and-setups\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "# np.set_printoptions(precision = 3, threshold = 15)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Libraries\n",
    "\n",
    "Uncomment and import any of the `sklearn` libraries below. In addition, boilerplate for importing `tensorflow` is also provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T05:17:20.563901Z",
     "start_time": "2022-05-25T05:17:19.616295Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import \n",
    "# from sklearn.model_selection import \n",
    "# from sklearn.preprocessing import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T05:23:50.950299Z",
     "start_time": "2022-05-25T05:23:49.591705Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.8.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f\"Tensorflow Version: {tf.__version__}\")\n",
    "\n",
    "# check physical devices\n",
    "# the given function is available only in tf 2x\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T05:24:54.310150Z",
     "start_time": "2022-05-25T05:24:54.289777Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Computing Available.\n"
     ]
    }
   ],
   "source": [
    "if len(tf.config.list_physical_devices(device_type = \"GPU\")):\n",
    "    # https://stackoverflow.com/q/38009682/6623589\n",
    "    # https://stackoverflow.com/a/59179238/6623589\n",
    "    print(\"GPU Computing Available.\")\n",
    "else:\n",
    "    print(\"GPU Computing Not Available. If `GPU` is present, check configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Argument(s)\n",
    "\n",
    "The global arguments are *notebook* specific, however they may also be extended to external libraries and functions on import. The *boilerplate* provides a basic ML directory structure which contains a directory for `data` and a separate directory for `output`. In addition, a separate directory (`data/processed`) is created to save processed dataset such that preprocessing can be avoided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T05:23:33.627167Z",
     "start_time": "2022-05-25T05:23:33.608510Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT = \"..\" # the document root is one level up, that contains all code structure\n",
    "DATA = join(ROOT, \"data\") # the directory contains all data files, subdirectory (if any) can also be used/defined\n",
    "\n",
    "# processed data directory can be used, such that preprocessing steps is not\n",
    "# required to run again-and-again each time on kernel restart\n",
    "PROCESSED_DATA = join(DATA, \"processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T05:23:33.866563Z",
     "start_time": "2022-05-25T05:23:33.854120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code Execution Started on: Wed, May 25 2022\n"
     ]
    }
   ],
   "source": [
    "# long projects can be overwhelming, and keeping track of files, outputs and\n",
    "# saved models can be intriguing! to help this out, `today` can be used. for\n",
    "# instance output can be stored at `output/<today>/` etc.\n",
    "# `today` is so configured that it permits windows/*.nix file/directory names\n",
    "today = dt.strftime(dt.strptime(ctime(), \"%a %b %d %H:%M:%S %Y\"), \"%a, %b %d %Y\")\n",
    "print(f\"Code Execution Started on: {today}\") # only date, name of the sub-directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T06:51:14.197935Z",
     "start_time": "2022-05-25T06:51:13.856920Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'join' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m OUTPUT_DIR \u001b[38;5;241m=\u001b[39m \u001b[43mjoin\u001b[49m(ROOT, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m, today)\n\u001b[0;32m      2\u001b[0m makedirs(OUTPUT_DIR, exist_ok \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# create dir if not exist\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# in addition create directory for images, saved models\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'join' is not defined"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = join(ROOT, \"output\", today)\n",
    "makedirs(OUTPUT_DIR, exist_ok = True) # create dir if not exist\n",
    "\n",
    "# in addition create directory for images, saved models\n",
    "IMAGE_DIR = join(ROOT, \"output\", \"images\", today)\n",
    "MODEL_DIR = join(ROOT, \"output\", \"savedmodels\", today)\n",
    "\n",
    "makedirs(IMAGE_DIR, exist_ok = True) # create dir if not exist\n",
    "makedirs(MODEL_DIR, exist_ok = True) # create dir if not exist\n",
    "\n",
    "# also create directory for `logs`\n",
    "LOGS_DIR = join(ROOT, \"logs\", \"BOILERPLATE\") # enter project code to distinguish\n",
    "makedirs(LOGS_DIR, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T05:36:04.278345Z",
     "start_time": "2022-05-25T05:36:03.909987Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LOGS_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mLOGS_DIR\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LOGS_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "print(LOGS_DIR) # logs file will be generated here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T05:23:37.753993Z",
     "start_time": "2022-05-25T05:23:37.735589Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.captureWarnings(True) # send warnings to log file automatically https://stackoverflow.com/a/37979724/6623589\n",
    "logging.basicConfig(\n",
    "    filename = join(LOGS_DIR, f\"{today}.log\"), # change `reports` file name\n",
    "    filemode = \"a\", # append logs to existing file, if file exists\n",
    "    format = \"%(asctime)s - %(name)s - CLASS:%(levelname)s:%(levelno)s:L#%(lineno)d - %(message)s\",\n",
    "    level = logging.DEBUG\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Defined Function(s)\n",
    "\n",
    "It is recommended that any UDFs are defined outside the scope of the *jupyter notebook* such that development/editing of function can be done more practically. As per *programming guidelines* as [`src`](https://fileinfo.com/extension/src) file/directory is beneficial in code development and/or production release. However, *jupyter notebook* requires *kernel restart* if any imported code file is changed in disc, for this frequently changing functions can be defined in this section.\n",
    "\n",
    "**Getting Started** with **`PYTHONPATH`**\n",
    "\n",
    "One must know what are [Environment Variable](https://medium.com/chingu/an-introduction-to-environment-variables-and-how-to-use-them-f602f66d15fa) and how to call/use them in your choice of programming language. Note that an environment variable is *case sensitive* in all operating systems (except windows, since DOS is not case sensitive). Generally, we can access environment variables from terminal/shell/command prompt as:\n",
    "\n",
    "```shell\n",
    "# macOS/*nix\n",
    "echo $VARNAME\n",
    "\n",
    "# windows\n",
    "echo %VARNAME%\n",
    "```\n",
    "\n",
    "Once you've setup your system with [`PYTHONPATH`](https://bic-berkeley.github.io/psych-214-fall-2016/using_pythonpath.html) as per [*python documentation*](https://docs.python.org/3/using/cmdline.html#envvar-PYTHONPATH) is an important directory where any `import` statements looks for based on their order of importance. If a source code/module is not available check necessary environment variables and/or ask the administrator for the source files.\n",
    "\n",
    "For testing purpose, the module boasts the use of `src`, `utils` and `config` directories. However, these directories are available at `ROOT` level, and thus using `sys.path.append()` to add directories while importing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T05:02:53.820581Z",
     "start_time": "2022-05-25T05:02:53.804003Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "logging.info(\"Appending `src/*` to Notebook-Path. Import any modules from `../src/*` to be used here.\")\n",
    "logging.info(\"Appending `utilities/*` to Notebook-Path. Import any modules from `../utilities/*` to be used here.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T04:56:41.730395Z",
     "start_time": "2022-05-25T04:56:41.711081Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "sys.path.append(join(ROOT, \"src\")) # source files\n",
    "sys.path.append(join(ROOT, \"src\", \"agents\")) # agents for an efficient rl model\n",
    "sys.path.append(join(ROOT, \"src\", \"engine\")) # ai/ml code engines for modelling\n",
    "sys.path.append(join(ROOT, \"src\", \"models\")) # defination of actual ai/ml model\n",
    "sys.path.append(join(ROOT, \"utilities\")) # provide a list of utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T05:10:39.190130Z",
     "start_time": "2022-05-25T05:10:39.169503Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def get_files(path : str) -> list:\n",
    "    \"\"\"Get a List of Files in a given Directory and its Sub-Directory\"\"\"\n",
    "    \n",
    "    files = []\n",
    "    for (_, _, file) in walk(path):\n",
    "        files.extend(file)\n",
    "        \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T05:11:16.263383Z",
     "start_time": "2022-05-25T05:11:16.241287Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# get a list of python code files available in directory\n",
    "# this can be used for logging purpose, or can also be used to quickly find a file\n",
    "__src_files__ = [file for file in get_files(join(ROOT, \"src\")) if file[-2:] == \"py\"]\n",
    "__utl_files__ = [file for file in get_files(join(ROOT, \"utilities\")) if file[-2:] == \"py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T05:11:23.855154Z",
     "start_time": "2022-05-25T05:11:23.833630Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "logging.debug(f\"`src/*` is now available to import. Available modules = {len(__src_files__)}\")\n",
    "logging.debug(f\"`utilities/*` is now available to import. Available modules = {len(__utl_files__)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Input File(s)\n",
    "\n",
    "A typical machine learning project revolves around six important stages (as available in [Amazon ML Life Cycle Documentation](https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/well-architected-machine-learning-lifecycle.html)). The notebook boilerplate is provided to address two pillars:\n",
    "\n",
    " 1. **Data Processing:** An integral part of any machine learning project, which is the most time consuming step! A brief introduction and best practices is available [here](https://towardsdatascience.com/introduction-to-data-preprocessing-in-machine-learning-a9fa83a5dc9d).\n",
    " 2. **Model Development:** From understanding to deployment, this section address development (training, validating and testing) of an machine learning model.\n",
    "\n",
    "![ML Life Cycle](https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/images/ml-lifecycle.png)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "TensorFlow 2.8.0 (GPU)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
