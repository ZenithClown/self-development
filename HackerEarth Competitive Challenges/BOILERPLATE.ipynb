{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = \"center\">Boilerplate/Template Design</h1>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Objective:** The file provides a simple *boilerplate* to concentrate on what is necessary, and stop doing same tasks! The boilerplate is also configured with certain [**nbextensions**](https://gitlab.com/ZenithClown/computer-configurations-and-setups) that I personally use. Install them, if required, else ignore them as they do not participate in any type of code-optimizations. For any new project *edit* this file or `File > Make a Copy` to get started with the project. Some settings and configurations are already provided, as mentioned below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Imports\n",
    "\n",
    "**PEP8 Style Guide** lists out the following [*guidelines*](https://peps.python.org/pep-0008/#imports) for imports:\n",
    " 1. Imports should be on separate lines,\n",
    " 2. Import order should be:\n",
    "    * standard library/modules,\n",
    "    * related third party imports,\n",
    "    * local application/user defined imports\n",
    " 3. Wildcard import (`*`) should be avoided, else specifically tagged with **`# noqa: F403`** as per `flake8` [(ignoring errors)](https://flake8.pycqa.org/en/3.1.1/user/ignoring-errors.html).\n",
    " 4. Avoid using relative imports; use explicit imports instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T11:26:31.987907Z",
     "start_time": "2022-08-08T11:26:31.983583Z"
    }
   },
   "outputs": [],
   "source": [
    "import os # funadamental library for handling\n",
    "import sys # append additional directories to list\n",
    "import time # for handing time objects, and pretty prints\n",
    "import warnings # display specified user warnings as required\n",
    "import datetime as dt # standard dattime handling and manipulation module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**`logging`**](https://docs.python.org/3/howto/logging.html) is a standard python module that is meant for tracking any events that happen during any software/code operations. This module is super powerful and helpful for code debugging and other purposes. The next section defines a `logging` configuration in **`../logs/`** directory. Modify the **`LOGS_DIR`** variable under *Global Arguments* to change the default directory. The module is configured with a simplistic approach, such that any `print())` statement can be update to `logging.LEVEL_NAME()` and the code will work. Use logging operations like:\n",
    "\n",
    "```python\n",
    " >> logging.debug(\"This is a Debug Message.\")\n",
    " >> logging.info(\"This is a Information Message.\")\n",
    " >> logging.warning(\"This is a Warning Message.\")\n",
    " >> logging.error(\"This is a ERROR Message.\")\n",
    " >> logging.critical(\"This is a CRITICAL Message.\")\n",
    "```\n",
    "\n",
    "Note: some directories related to logging is created by default. This can be updated/changed in the following configuration section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T11:25:43.123989Z",
     "start_time": "2022-08-08T11:25:43.112632Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging # configure logging on `global arguments` section, as file path is required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Frame, NumPy and Visualization Libraries\n",
    "\n",
    "Daily use libraries like `pandas`, `numpy` is available for import along with *display* settings in a python notebook. Generally, I prefer to use `matplotlib` and `seaborn` which is imported below with certain configurations as mentioned. Stylesheet is available [here](https://gitlab.com/ZenithClown/computer-configurations-and-setups/-/blob/master/default-style.mplstyle), and the code snippets (for VS code) is available [here](https://gitlab.com/ZenithClown/computer-configurations-and-setups/-/tree/master/template/snippets/vscode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "%precision 3\n",
    "# %matplotlib inline\n",
    "# sns.set_style('whitegrid');\n",
    "# plt.style.use('default-style'); # https://gitlab.com/ZenithClown/computer-configurations-and-setups\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "# np.set_printoptions(precision = 3, threshold = 15)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Libraries\n",
    "\n",
    "Well, Machine Learning involves pretty much everything from ETA to model development and deployment (for E2E applications). This section can be used to import basic and/or standard libraries to acheive the same. Uncomment and import any of the `sklearn` libraries below. In addition, boilerplate for importing `tensorflow` is also provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T05:17:20.563901Z",
     "start_time": "2022-05-25T05:17:19.616295Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import \n",
    "# from sklearn.model_selection import \n",
    "# from sklearn.preprocessing import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T05:23:50.950299Z",
     "start_time": "2022-05-25T05:23:49.591705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.8.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# print(f\"Tensorflow Version: {tf.__version__}\")\n",
    "\n",
    "# # check physical devices\n",
    "# # the given function is available only in tf 2x\n",
    "# tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T05:24:54.310150Z",
     "start_time": "2022-05-25T05:24:54.289777Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Computing Available.\n"
     ]
    }
   ],
   "source": [
    "if len(tf.config.list_physical_devices(device_type = \"GPU\")):\n",
    "    # https://stackoverflow.com/q/38009682/6623589\n",
    "    # https://stackoverflow.com/a/59179238/6623589\n",
    "    print(\"GPU Computing Available.\")\n",
    "else:\n",
    "    print(\"GPU Computing Not Available. If `GPU` is present, check configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Argument(s)\n",
    "\n",
    "The global arguments are *notebook* specific, however they may also be extended to external libraries and functions on import. The *boilerplate* provides a basic ML directory structure which contains a directory for `data` and a separate directory for `output`. In addition, a separate directory (`data/processed`) is created to save processed dataset such that preprocessing can be avoided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T11:26:38.164730Z",
     "start_time": "2022-08-08T11:26:38.151616Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT = \"..\" # the document root is one level up, that contains all code structure\n",
    "DATA = os.path.join(ROOT, \"data\") # the directory contains all data files, subdirectory (if any) can also be used/defined\n",
    "\n",
    "# processed data directory can be used, such that preprocessing steps is not\n",
    "# required to run again-and-again each time on kernel restart\n",
    "PROCESSED_DATA = os.path.join(DATA, \"processed\")\n",
    "\n",
    "# additional data directory can be project specific, or may be available from a global datasets collections/websites\n",
    "# these data are either directly imported from URL and/or saved in the `additional` directory as provided below\n",
    "ADDITIONAL_DATA = os.path.join(DATA, \"additional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T11:26:47.507778Z",
     "start_time": "2022-08-08T11:26:47.487763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code Execution Started on: Mon, Aug 08 2022\n"
     ]
    }
   ],
   "source": [
    "# long projects can be overwhelming, and keeping track of files, outputs and\n",
    "# saved models can be intriguing! to help this out, `today` can be used. for\n",
    "# instance output can be stored at `output/<today>/` etc.\n",
    "# `today` is so configured that it permits windows/*.nix file/directory names\n",
    "today = dt.datetime.strftime(dt.datetime.strptime(time.ctime(), \"%a %b %d %H:%M:%S %Y\"), \"%a, %b %d %Y\")\n",
    "print(f\"Code Execution Started on: {today}\") # only date, name of the sub-directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T11:27:23.592932Z",
     "start_time": "2022-08-08T11:27:23.584899Z"
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.path.join(ROOT, \"output\", today)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok = True) # create dir if not exist\n",
    "\n",
    "# in addition create directory for images, saved models\n",
    "IMAGE_DIR = os.path.join(ROOT, \"output\", \"images\", today)\n",
    "MODEL_DIR = os.path.join(ROOT, \"output\", \"savedmodels\", today)\n",
    "\n",
    "os.makedirs(IMAGE_DIR, exist_ok = True) # create dir if not exist\n",
    "os.makedirs(MODEL_DIR, exist_ok = True) # create dir if not exist\n",
    "\n",
    "# also create directory for `logs`\n",
    "LOGS_DIR = os.path.join(os.sep, \"D:\", os.sep, \"logs\", \"BOILERPLATE\") # enter project code to distinguish\n",
    "os.makedirs(LOGS_DIR, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T11:27:25.519090Z",
     "start_time": "2022-08-08T11:27:25.511149Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\logs\\BOILERPLATE\n"
     ]
    }
   ],
   "source": [
    "print(LOGS_DIR) # logs file will be generated here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-08T11:27:37.802349Z",
     "start_time": "2022-08-08T11:27:37.798025Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.captureWarnings(True) # send warnings to log file automatically https://stackoverflow.com/a/37979724/6623589\n",
    "logging.basicConfig(\n",
    "    filename = os.path.join(LOGS_DIR, f\"{today}.log\"), # change `reports` file name\n",
    "    filemode = \"a\", # append logs to existing file, if file exists\n",
    "    format = \"%(asctime)s - %(name)s - CLASS:%(levelname)s:%(levelno)s:L#%(lineno)d - %(message)s\",\n",
    "    level = logging.DEBUG\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Defined Function(s)\n",
    "\n",
    "It is recommended that any UDFs are defined outside the scope of the *jupyter notebook* such that development/editing of function can be done more practically. As per *programming guidelines* as [`src`](https://fileinfo.com/extension/src) file/directory is beneficial in code development and/or production release. However, *jupyter notebook* requires *kernel restart* if any imported code file is changed in disc, for this frequently changing functions can be defined in this section.\n",
    "\n",
    "**Getting Started** with **`PYTHONPATH`**\n",
    "\n",
    "One must know what are [Environment Variable](https://medium.com/chingu/an-introduction-to-environment-variables-and-how-to-use-them-f602f66d15fa) and how to call/use them in your choice of programming language. Note that an environment variable is *case sensitive* in all operating systems (except windows, since DOS is not case sensitive). Generally, we can access environment variables from terminal/shell/command prompt as:\n",
    "\n",
    "```shell\n",
    "# macOS/*nix\n",
    "echo $VARNAME\n",
    "\n",
    "# windows\n",
    "echo %VARNAME%\n",
    "```\n",
    "\n",
    "Once you've setup your system with [`PYTHONPATH`](https://bic-berkeley.github.io/psych-214-fall-2016/using_pythonpath.html) as per [*python documentation*](https://docs.python.org/3/using/cmdline.html#envvar-PYTHONPATH) is an important directory where any `import` statements looks for based on their order of importance. If a source code/module is not available check necessary environment variables and/or ask the administrator for the source files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Input File(s)\n",
    "\n",
    "A typical machine learning project revolves around six important stages (as available in [Amazon ML Life Cycle Documentation](https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/well-architected-machine-learning-lifecycle.html)). The notebook boilerplate is provided to address two pillars:\n",
    "\n",
    " 1. **Data Processing:** An integral part of any machine learning project, which is the most time consuming step! A brief introduction and best practices is available [here](https://towardsdatascience.com/introduction-to-data-preprocessing-in-machine-learning-a9fa83a5dc9d).\n",
    " 2. **Model Development:** From understanding to deployment, this section address development (training, validating and testing) of an machine learning model.\n",
    "\n",
    "![ML Life Cycle](https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/images/ml-lifecycle.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "TensorFlow 2.8.0 (GPU)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
